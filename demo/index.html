<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta http-equiv="x-ua-compatible" content="ie=edge"/><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"/><style data-href="/styles.0116d208c84ecec8ed57.css">@import url(https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700,700i&display=swap);@import url(https://fonts.googleapis.com/css?family=Playfair+Display:900&display=swap);:root{overflow-y:scroll;--font-title:"Playfair Display",serif;--font-sans-serif:"Open Sans",sans-serif;--font-serif:serif;--font-mono:monospace;--font-light:300;--font-normal:400;--font-bold:700;--font-heavy:900}body.light{--color-bg:hsla(0,0%,100%,0.9);--color-font:rgba(0,0,0,0.8);--color-postcard:rgba(0,0,0,0.1);--color-blue:#007aff;--color-green:#34c759;--color-indigo:#5856d6;--color-orange:#ff9500;--color-pink:#ff2d55;--color-purple:#af52de;--color-red:#ff3b30;--color-teal:#5ac8fa;--color-yellow:#fc0;--color-gray-1:#8e8e93;--color-gray-2:#aeaeb2;--color-gray-3:#c7c7cc;--color-gray-4:#d1d1d6;--color-gray-5:#e5e5ea;--color-gray-6:#f2f2f7}body.dark{--color-bg:rgba(0,0,0,0.9);--color-font:hsla(0,0%,100%,0.8);--color-postcard:hsla(0,0%,100%,0.1);--color-blue:#0a84ff;--color-green:#30d158;--color-indigo:#5e5ce6;--color-orange:#ff9f0a;--color-pink:#ff375f;--color-purple:#bf5af2;--color-red:#ff453a;--color-teal:#64d2ff;--color-yellow:#ffd60a;--color-gray-1:#8e8e93;--color-gray-2:#636366;--color-gray-3:#48484a;--color-gray-4:#3a3a3c;--color-gray-5:#2c2c2e;--color-gray-6:#1c1c1e}body{font-family:var(--font-sans-serif);background-color:var(--color-bg);color:var(--color-font);caret-color:var(--color-font);-webkit-transition:color,background-color .5s ease 0s;transition:color,background-color .5s ease 0s;letter-spacing:-.0125em}::selection{background:var(--color-teal)}hr{border:0;height:.0625rem;background-color:var(--color-gray-2)}.site-container{margin:auto;padding:auto;max-width:45rem}.header-container{display:flex;align-items:baseline;margin:0 .5em}@media (max-width:540px){.header-container{flex-wrap:wrap}#header-nav-first{margin-left:0}}.header-container a{text-decoration:none;color:inherit}.header-container a::selection,.header-container div::selection{background:transparent}.header-title{text-transform:uppercase;font-family:var(--font-title);font-size:2.75em;font-weight:900;white-space:nowrap;letter-spacing:0}.nav-container{display:flex;width:100%;justify-content:space-between;font-size:.875em}.header-nav{justify-content:flex-start}.header-link,.header-nav{list-style:none;display:flex;padding:0;margin:.25rem 0}.header-link{justify-content:flex-end}.header-link li,.header-nav li{margin-left:1.5em}.tog-checkbox{display:none}.tog-text{cursor:pointer}.footer-copyright{text-align:center;font-size:.875em}.footer-gatsby{text-decoration:none;color:inherit}.post-card{border:.0625em solid var(--color-postcard);border-radius:.3em;box-shadow:0 .0625em .25em var(--color-postcard);margin-top:.5em;margin-bottom:1.5em;padding:2em 1.5em;cursor:default}.post-card h1{font-size:2em;margin-top:0;margin-bottom:0;letter-spacing:-.025em}.post-card a{text-decoration:none;color:inherit}.post-card p{margin-bottom:0;margin-top:.75em}.post-card small{font-size:.8125em}.post-card img{margin-top:.75em;width:100%}.tag-item{margin-right:.375em}.post-header{text-align:center}.post-header h1{font-size:2.5em;letter-spacing:-.025em;margin-top:.8125em;margin-bottom:0}.post-header p{font-size:.8125em;margin-top:.8125em}.search-box-container{display:flex;flex-direction:column;align-items:center}.search-box{margin:2em auto;width:35%;border-radius:.625em;border:.0625em solid var(--color-font);box-shadow:0 .0625em .25em var(--color-postcard);padding:.8125em;font-family:inherit;color:inherit;background-color:transparent}.search-box:focus{outline:none}.search-box::-webkit-input-placeholder{color:var(--color-gray-1)}.search-box:-ms-input-placeholder{color:var(--color-gray-1)}.search-box::-ms-input-placeholder{color:var(--color-gray-1)}.search-box::placeholder{color:var(--color-gray-1)}.tag-archive-container{display:flex;justify-content:center;flex-wrap:wrap}.tag-archive-item{border:.0625em solid var(--color-postcard);border-radius:.3em;box-shadow:0 .0625em .25em var(--color-postcard);margin:.5em;padding:.2em .6em}.tag-archive-link{text-decoration:none;color:inherit}.pagenator{display:flex;justify-content:space-between;margin-bottom:1em;font-size:.875em}.pagenator-link svg{fill:var(--color-font)}.pagenator-unlinked svg{fill:transparent}.pagenator a::selection,.pagenator div::selection{background:transparent}.pagenator svg{width:.75rem;height:.75rem}.post-card-readmore{margin-top:.375rem;font-size:.875em;color:var(--color-blue)}.post-card-readmore span::selection{background:transparent}.post-card-readmore a:hover{text-decoration:underline}.post-card-readmore svg{width:.5rem;height:.5rem;margin-left:.125rem;fill:var(--color-blue)}.post-nav{display:flex;flex-wrap:wrap;justify-content:space-between;list-style:none;padding:0;font-size:1.125em}.post-nav ::selection{background:transparent}.post-nav a{text-decoration:none;color:inherit;display:flex;align-items:baseline}.post-nav svg{width:.8125rem;height:.8125rem;fill:var(--color-font)}.post-nav-prev{margin-left:.125rem}.post-nav-next{margin-right:.125rem}article .tag-container{text-align:right}article .tag-container a{text-decoration:none;color:inherit;font-size:.875em}</style><meta name="generator" content="Gatsby 2.18.12"/><style type="text/css">.gatsby-resp-image-image{width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;color:transparent;}</style><link rel="alternate" type="application/rss+xml" href="/rss.xml"/><link rel="icon" href="/icons/icon-48x48.png?v=edf3d310d67f8284a562bc3a58c3e761"/><link rel="manifest" href="/manifest.webmanifest"/><meta name="theme-color" content="#663399"/><link rel="apple-touch-icon" sizes="48x48" href="/icons/icon-48x48.png?v=edf3d310d67f8284a562bc3a58c3e761"/><link rel="apple-touch-icon" sizes="72x72" href="/icons/icon-72x72.png?v=edf3d310d67f8284a562bc3a58c3e761"/><link rel="apple-touch-icon" sizes="96x96" href="/icons/icon-96x96.png?v=edf3d310d67f8284a562bc3a58c3e761"/><link rel="apple-touch-icon" sizes="144x144" href="/icons/icon-144x144.png?v=edf3d310d67f8284a562bc3a58c3e761"/><link rel="apple-touch-icon" sizes="192x192" href="/icons/icon-192x192.png?v=edf3d310d67f8284a562bc3a58c3e761"/><link rel="apple-touch-icon" sizes="256x256" href="/icons/icon-256x256.png?v=edf3d310d67f8284a562bc3a58c3e761"/><link rel="apple-touch-icon" sizes="384x384" href="/icons/icon-384x384.png?v=edf3d310d67f8284a562bc3a58c3e761"/><link rel="apple-touch-icon" sizes="512x512" href="/icons/icon-512x512.png?v=edf3d310d67f8284a562bc3a58c3e761"/><title data-react-helmet="true">Audio examples | 192</title><meta data-react-helmet="true" name="description" content="Audio examples accompanying paper ID 192 for the 19th International Conference of Machine Learning and Applications."/><meta data-react-helmet="true" property="og:title" content="Audio examples"/><meta data-react-helmet="true" property="og:description" content="Audio examples accompanying paper ID 192 for the 19th International Conference of Machine Learning and Applications."/><meta data-react-helmet="true" property="og:type" content="website"/><meta data-react-helmet="true" name="twitter:card" content="summary"/><meta data-react-helmet="true" name="twitter:creator" content="Vaporwavy"/><meta data-react-helmet="true" name="twitter:title" content="Audio examples"/><meta data-react-helmet="true" name="twitter:description" content="Audio examples accompanying paper ID 192 for the 19th International Conference of Machine Learning and Applications."/><link as="script" rel="preload" href="/webpack-runtime-d5f93bec9ea28c974d9e.js"/><link as="script" rel="preload" href="/app-1f15bb84768e1d0aceed.js"/><link as="script" rel="preload" href="/styles-b20442fc9111cfe40353.js"/><link as="script" rel="preload" href="/commons-8886d4eca7d37a0ab99a.js"/><link as="script" rel="preload" href="/component---src-templates-blog-post-js-615057d9e507467c8695.js"/><link as="fetch" rel="preload" href="/page-data/demo/page-data.json" crossorigin="anonymous"/></head><body><script>
void function() {
  window.__onThemeChange = function() {}

  var preferredTheme
  try {
    preferredTheme = localStorage.getItem('theme')
  } catch (err) { }

  function setTheme(newTheme) {
    window.__theme = newTheme
    preferredTheme = newTheme
    document.body.className = newTheme
    window.__onThemeChange(newTheme)
  }

  window.__setPreferredTheme = function(newTheme) {
    setTheme(newTheme)
    try {
      localStorage.setItem('theme', newTheme)
    } catch (err) {}
  }

  var darkQuery = window.matchMedia('(prefers-color-scheme: dark)')
  darkQuery.addListener(function(e) {
    window.__setPreferredTheme(e.matches ? 'dark' : 'light')
  })

  setTheme(preferredTheme || (darkQuery.matches ? 'dark' : 'light'))
}()
    </script><div id="___gatsby"><div style="outline:none" tabindex="-1" role="group" id="gatsby-focus-wrapper"><div class="site-container"><div class="header-container"><a class="header-title" href="/">192</a><div class="nav-container"><ul class="header-nav"><li id="header-nav-first"><a href="/tags">Tags</a></li><li><a href="/search">Search</a></li><li><div class="toggler"><label class="tog"><input type="checkbox" class="tog-checkbox"/><div class="tog-text">Dark</div></label></div></li></ul></div></div><main><hr/><article><header class="post-header"><h1>Audio examples</h1><p>July 17, 2020</p></header><section><p>Audio examples accompanying paper ID 192 for 19th International Conference of Machine Learning and Applications.</p>
<p>While listening to the following audio examples, please note that some sonic artifacts are present here and also in other state-of-the-art singing voice conversion methods (e.g., <a href="#ref">1</a>). The reduction of such artifacts is not the main target of our research and will be tackled by a research community in the future. Please focus on listening to the conversion of musical characteristics such as timbre and singing style.</p>
<h1>JPSV-120E Dataset - Female (Song 13 &#x26; ID 27)</h1>
<p>Each presented audio example follows song and singer IDs in Tables I and II in the paper. All examples are 16-bit 22050 Hz WAV files.</p>
<figure>
<figcaption><b>Ground truth (female)</b></figcaption>
	<audio controls
		src="/4663f12e58405beba0696177a7689aeb/A_SOURCE_female_JP.wav">
	</audio>
</figure>
<figure>
<figcaption><b>Reconstruction (female)</b></figcaption>
<figcaption>Generator trained using space <b>Zc = 4</b></figcaption>
	<audio controls
		src="/b8f06b10a172d58ec329ff30471eec9e/A_Z4_RECON_female_JP.wav">
	</audio>
</figure>
<figure>
<figcaption><b>Voice Conversion (female &rarr; female)</b></figcaption>
<figcaption>4 examples generated with a trained model using space <b>Zc = 4</b></figcaption>
	<audio controls
		src="/3e47b5ab775b91687feb46a790a9020f/A4_Z4_female_female_JP.wav">
	</audio>
	<audio controls
		src="/c359f14ba8f18a35a8c13db30f435597/A3_Z4_female_female_JP.wav">
	</audio>
	<audio controls
		src="/1ffc5d340c0ecaf3214e58daabe95bc9/A2_Z4_female_female_JP.wav">
	</audio>
	<audio controls
		src="/ed900bb0df13fbba88dd1e9db97fc108/A1_Z4_female_female_JP.wav">
	</audio>
	<figcaption>Above examples show varied timbres and successful conversions to different singers</figcaption>
</figure>
<figure>
<figcaption><b>Voice Conversion (female &rarr; male)</b></figcaption>
<figcaption>4 examples generated with a trained model using space <b>Zc = 4</b></figcaption>
	<audio controls
		src="/8fbbb81436adb08ffa3d9058bb582de3/A4_Z4_female_male_JP.wav">
	</audio>
	<audio controls
		src="/2c813a7402bec7c7f66596274f6f0ade/A3_Z4_female_male_JP.wav">
	</audio>
	<audio controls
		src="/32dd2c65980c1c77706b48b43c064d06/A2_Z4_female_male_JP.wav">
	</audio>
	<audio controls
		src="/410176c5111cf8f85a2354999ea5a81e/A1_Z4_female_male_JP.wav">
	</audio>
	<figcaption>Above examples show varied timbres and successful conversions to different singers</figcaption>
</figure>
<figure>
<figcaption><b>Voice Conversion (female &rarr; male)</b></figcaption>
<figcaption>Generator trained using space <b>Zc = 100</b></figcaption>
	<audio controls
		src="/cdadbf474ae11634f903c9cb6f5eac6d/A1_Z100_female_male_JP.wav">
	</audio>
<figcaption>Example sounds almost the same as the ground truth with <b>no voice conversion</b></figcaption>
</figure>
<h1>JPSV-120E Dataset - Male (Song 56 &#x26; ID 04)</h1>
<p>Each presented audio example follows song and singer IDs in Tables I and II in the paper. All examples are 16-bit 22050 Hz WAV files.</p>
<figure>
<figcaption><b>Ground truth (male)</b></figcaption>
	<audio controls
		src="/777eaaf8d857127edec70b43f2ed9956/A_SOURCE_male_JP.wav">
	</audio>
</figure>
<figure>
<figcaption><b>Reconstruction (male)</b></figcaption>
<figcaption>Generator trained using space <b>Zc = 4</b></figcaption>
	<audio controls
		src="/3f0dd5c401ebfb24cdfcb201e4adc267/A_Z4_RECON_male_JP.wav">
	</audio>
</figure>
<figure>
<figcaption><b>Voice Conversion (male &rarr; female)</b></figcaption>
<figcaption>4 examples generated with a trained model using space <b>Zc = 4</b></figcaption>
	<audio controls
		src="/02bf553b94e4ddc9aaf912710b4c19e9/A4_Z4_male_female_JP.wav">
	</audio>
	<audio controls
		src="/291e053b5d306984ce34a4ca590bbb6d/A3_Z4_male_female_JP.wav">
	</audio>
	<audio controls
		src="/af32cb694db90e90c8e27e85845cb05d/A2_Z4_male_female_JP.wav">
	</audio>
	<audio controls
		src="/42cb8bcb7224fd6e83bdcfb206819898/A1_Z4_male_female_JP.wav">
	</audio>
	<figcaption>Above examples show varied timbres and successful conversions to different singers</figcaption>
</figure>
<figure>
<figcaption><b>Voice Conversion (male &rarr; male)</b></figcaption>
<figcaption>4 examples generated with a trained model using space <b>Zc = 4</b></figcaption>
	<audio controls
		src="/11c61cd98c665f1bb01e9ac1df4aafab/A1_Z4_male_male_JP.wav">
	</audio>
	<audio controls
		src="/f47f8b0e0369df05e4e9c68bfab6912b/A3_Z4_male_male_JP.wav">
	</audio>
	<audio controls
		src="/b49cf6fb7f670f266821b3792e469952/A2_Z4_male_male_JP.wav">
	</audio>
	<audio controls
		src="/d3faf8e9c988da241fd277a8ff18d3bd/A4_Z4_male_male_JP.wav">
	</audio>
	<figcaption>Above examples show varied timbres and successful conversions to different singers</figcaption>
</figure>
<figure>
<figcaption><b>Voice Conversion (male &rarr; female)</b></figcaption>
<figcaption>Generator trained using space <b>Zc = 100</b></figcaption>
	<audio controls
		src="/c256cd88fb649e8572ab7f6861524c24/A4_Z100_male_female_JP.wav">
	</audio>
<figcaption>Example sounds almost the same as the ground truth with <b>no voice conversion</b></figcaption>
</figure>
<h1>NUS-48E Dataset - Female (Song 18 &#x26; ID ADIZ)</h1>
<p>Each presented audio example follows song and singer IDs in the original NUS-48E dataset <a href="#ref">2</a>. All examples are 16-bit 22050 Hz WAV files.</p>
<figure>
<figcaption><b>Ground truth (female)</b></figcaption>
	<audio controls
		src="/a2c4984f45c0d226c6d880f04fd24e8f/A_SOURCE_female_EN.wav">
	</audio>
</figure>
<figure>
<figcaption><b>Reconstruction (female)</b></figcaption>
<figcaption>Generator trained using space <b>Zc = 4</b></figcaption>
	<audio controls
		src="/350a05c4f669623571cfc28a855cf104/A_Z4_RECON_female_EN.wav">
	</audio>
</figure>
<figure>
<figcaption><b>Voice Conversion (female &rarr; female)</b></figcaption>
<figcaption>4 examples generated with a trained model using space <b>Zc = 4</b></figcaption>
	<audio controls
		src="/8ab87d418ccf41a6a2201fa1b97fa728/A4_Z4_female_female_EN.wav">
	</audio>
	<audio controls
		src="/dccc4df2fa6ae747e9529ea84deb97e7/A3_Z4_female_female_EN.wav">
	</audio>
	<audio controls
		src="/c57d12cf27cef182d95b629a19d55f98/A2_Z4_female_female_EN.wav">
	</audio>
	<audio controls
		src="/db01ed0d7b338f63bef626f24e8ddeb8/A1_Z4_female_female_EN.wav">
	</audio>
	<figcaption>Above examples show varied timbres and successful conversions to different singers</figcaption>
</figure>
<figure>
<figcaption><b>Voice Conversion (female &rarr; male)</b></figcaption>
<figcaption>4 examples generated with a trained model using space <b>Zc = 4</b></figcaption>
	<audio controls
		src="/3a2aaebc3b2dc1e37ee626654f61a7a8/A4_Z4_female_male_EN.wav">
	</audio>
	<audio controls
		src="/df6c927fffc03b27c967d0ba53e14723/A3_Z4_female_male_EN.wav">
	</audio>
	<audio controls
		src="/3114f9db09f0ccb73513b25aa41564c1/A2_Z4_female_male_EN.wav">
	</audio>
	<audio controls
		src="/deaa936ec236b067546f0d54aee80804/A1_Z4_female_male_EN.wav">
	</audio>
	<figcaption>Above examples show varied timbres and successful conversions to different singers</figcaption>
</figure>
<figure>
<figcaption><b>Voice Conversion (female &rarr; male)</b></figcaption>
<figcaption>Generator trained using space <b>Zc = 100</b></figcaption>
	<audio controls
		src="/66c76b2e6117ae05c15614fa78b47fe7/A1_Z100_female_male_EN.wav">
	</audio>
<figcaption>Example sounds almost the same as the ground truth with <b>no voice conversion</b></figcaption>
</figure>
<h1>NUS-48E Dataset - Male (Song 15 &#x26; ID JLEE)</h1>
<p>Each presented audio example follows song and singer IDs in the original NUS-48E dataset <a href="#ref">2</a>. All examples are 16-bit 22050 Hz WAV files.</p>
<figure>
<figcaption><b>Ground truth (male)</b></figcaption>
	<audio controls
		src="/0de36fe393d7a1030f7c0b93e1ba1ad2/A_SOURCE_male_EN.wav">
	</audio>
</figure>
<figure>
<figcaption><b>Reconstruction (male)</b></figcaption>
<figcaption>Generator trained using space <b>Zc = 4</b></figcaption>
	<audio controls
		src="/30f3bddb135909dded859dab5f8895ca/A_Z4_RECON_male_EN.wav">
	</audio>
</figure>
<figure>
<figcaption><b>Voice Conversion (male &rarr; female)</b></figcaption>
<figcaption>4 examples generated with a trained model using space <b>Zc = 4</b></figcaption>
	<audio controls
		src="/a4a0387cfea584fd306a27336356237d/A4_Z4_male_female_EN.wav">
	</audio>
	<audio controls
		src="/347b18dde7f7b9edf65dc40eb8aa133e/A3_Z4_male_female_EN.wav">
	</audio>
	<audio controls
		src="/554001cdcf1f2da765a5df2001b3d5d1/A2_Z4_male_female_EN.wav">
	</audio>
	<audio controls
		src="/9600978c0728d146ac70538c9e56bb2e/A1_Z4_male_female_EN.wav">
	</audio>
	<figcaption>Above examples show varied timbres and successful conversions to different singers</figcaption>
</figure>
<figure>
<figcaption><b>Voice Conversion (male &rarr; male)</b></figcaption>
<figcaption>4 examples generated with a trained model using space <b>Zc = 4</b></figcaption>
	<audio controls
		src="/218490b3b739dc6926b21f0d28d738b6/A1_Z4_male_male_EN.wav">
	</audio>
	<audio controls
		src="/6e5df02c893cdc7c818ac3573b2bc6e1/A3_Z4_male_male_EN.wav">
	</audio>
	<audio controls
		src="/3f8e8b8ab61c8c40be1e295196794c5d/A2_Z4_male_male_EN.wav">
	</audio>
	<audio controls
		src="/a752097a5260c8527451e5f87bd2378b/A4_Z4_male_male_EN.wav">
	</audio>
	<figcaption>Above examples show varied timbres and successful conversions to different singers</figcaption>
</figure>
<figure>
<figcaption><b>Voice Conversion (male &rarr; female)</b></figcaption>
<figcaption>Generator trained using space <b>Zc = 100</b></figcaption>
	<audio controls
		src="/714e82a97469c6856baf67ce2184a0b9/A4_Z100_male_female_EN.wav">
	</audio>
<figcaption>Example sounds almost the same as the ground truth with <b>no voice conversion</b></figcaption>
</figure>
<h1><a name="ref">References</a></h1>
<p>[1] <a href="https://ismir19-217.github.io/icassp20-audio-sample/">Yin-Jyun Luo et al. “Singing voice conversion with disentangled representations of singer and vocal technique using variational autoencoders”. In: IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). 2020.</a></p>
<p>[2]  <a href="https://smcnus.comp.nus.edu.sg/nus-48e-sung-and-spoken-lyrics-corpus/">Zhiyan Duan et al. “The NUS sung and spoken lyrics corpus: A quantitative comparison of singing and speech”. In: IEEE Asia-Pacific Signal and InformationProcessing Association Annual Summit and Conference (APSIPA ASC). 2013.</a></p></section><div class="tag-container"><a class="tag-item" href="/tags/demo">#<!-- -->demo</a></div></article><hr/><nav><ul class="post-nav"><li></li><li></li></ul></nav></main><footer class="footer-copyright">© <!-- -->2020<!-- --> <!-- -->192<!-- -->, Built with<!-- --> <a class="footer-gatsby" href="https://www.gatsbyjs.org">Gatsby</a></footer></div></div></div><script id="gatsby-script-loader">/*<![CDATA[*/window.pagePath="/demo/";/*]]>*/</script><script id="gatsby-chunk-mapping">/*<![CDATA[*/window.___chunkMapping={"app":["/app-1f15bb84768e1d0aceed.js"],"component---node-modules-gatsby-plugin-offline-app-shell-js":["/component---node-modules-gatsby-plugin-offline-app-shell-js-bb5433fc5c978771af2b.js"],"component---src-templates-blog-post-js":["/component---src-templates-blog-post-js-615057d9e507467c8695.js"],"component---src-templates-blog-index-js":["/component---src-templates-blog-index-js-6669b4d2fe5146961224.js"],"component---src-templates-tag-index-js":["/component---src-templates-tag-index-js-c915debea13949814b91.js"],"component---src-pages-404-js":["/component---src-pages-404-js-9d4d43b7ec78ac94a066.js"],"component---src-pages-search-js":["/component---src-pages-search-js-71b6bdbee9d65185d073.js"],"component---src-pages-tags-js":["/component---src-pages-tags-js-6e5678ae212d1da68d48.js"]};/*]]>*/</script><script src="/component---src-templates-blog-post-js-615057d9e507467c8695.js" async=""></script><script src="/commons-8886d4eca7d37a0ab99a.js" async=""></script><script src="/styles-b20442fc9111cfe40353.js" async=""></script><script src="/app-1f15bb84768e1d0aceed.js" async=""></script><script src="/webpack-runtime-d5f93bec9ea28c974d9e.js" async=""></script></body></html>