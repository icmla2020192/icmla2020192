{"componentChunkName":"component---src-templates-blog-post-js","path":"/demo/","result":{"data":{"site":{"siteMetadata":{"title":"192"}},"markdownRemark":{"id":"6f5f6ae2-472a-55b0-8ae4-2db67a83834b","excerpt":"Audio examples accompanying paper ID 192 for 19th International Conference of Machine Learning and Applications. JPSV-120E Dataset - Female (Song 13 & ID 2…","html":"<p>Audio examples accompanying paper ID 192 for 19th International Conference of Machine Learning and Applications.</p>\n<h1>JPSV-120E Dataset - Female (Song 13 &#x26; ID 27)</h1>\n<p>Each presented audio example follows song and singer IDs in Tables I and II in the paper. All examples are 16-bit 22050 Hz WAV files.</p>\n<figure>\n<figcaption><b>Ground truth (female)</b></figcaption>\n\t<audio controls\n\t\tsrc=\"/4663f12e58405beba0696177a7689aeb/A_SOURCE_female_JP.wav\">\n\t</audio>\n</figure>\n<figure>\n<figcaption><b>Reconstruction (female)</b></figcaption>\n<figcaption>Generator trained using space <b>Zc = 4</b></figcaption>\n\t<audio controls\n\t\tsrc=\"/b8f06b10a172d58ec329ff30471eec9e/A_Z4_RECON_female_JP.wav\">\n\t</audio>\n</figure>\n<figure>\n<figcaption><b>Voice Conversion (female &rarr; female)</b></figcaption>\n<figcaption>4 examples generated with a trained model using space <b>Zc = 4</b></figcaption>\n\t<audio controls\n\t\tsrc=\"/3e47b5ab775b91687feb46a790a9020f/A4_Z4_female_female_JP.wav\">\n\t</audio>\n\t<audio controls\n\t\tsrc=\"/c359f14ba8f18a35a8c13db30f435597/A3_Z4_female_female_JP.wav\">\n\t</audio>\n\t<audio controls\n\t\tsrc=\"/1ffc5d340c0ecaf3214e58daabe95bc9/A2_Z4_female_female_JP.wav\">\n\t</audio>\n\t<audio controls\n\t\tsrc=\"/ed900bb0df13fbba88dd1e9db97fc108/A1_Z4_female_female_JP.wav\">\n\t</audio>\n\t<figcaption>Above examples show varied timbres and successful conversions to different singers</figcaption>\n</figure>\n<figure>\n<figcaption><b>Voice Conversion (female &rarr; male)</b></figcaption>\n<figcaption>4 examples generated with a trained model using space <b>Zc = 4</b></figcaption>\n\t<audio controls\n\t\tsrc=\"/8fbbb81436adb08ffa3d9058bb582de3/A4_Z4_female_male_JP.wav\">\n\t</audio>\n\t<audio controls\n\t\tsrc=\"/2c813a7402bec7c7f66596274f6f0ade/A3_Z4_female_male_JP.wav\">\n\t</audio>\n\t<audio controls\n\t\tsrc=\"/32dd2c65980c1c77706b48b43c064d06/A2_Z4_female_male_JP.wav\">\n\t</audio>\n\t<audio controls\n\t\tsrc=\"/410176c5111cf8f85a2354999ea5a81e/A1_Z4_female_male_JP.wav\">\n\t</audio>\n\t<figcaption>Above examples show varied timbres and successful conversions to different singers</figcaption>\n</figure>\n<figure>\n<figcaption><b>Voice Conversion (female &rarr; male)</b></figcaption>\n<figcaption>Generator trained using space <b>Zc = 100</b></figcaption>\n\t<audio controls\n\t\tsrc=\"/cdadbf474ae11634f903c9cb6f5eac6d/A1_Z100_female_male_JP.wav\">\n\t</audio>\n<figcaption>Example sounds almost the same as the ground truth with <b>no voice conversion</b></figcaption>\n</figure>\n<h1>JPSV-120E Dataset - Male (Song 56 &#x26; ID 04)</h1>\n<p>Each presented audio example follows song and singer IDs in Tables I and II in the paper. All examples are 16-bit 22050 Hz WAV files.</p>\n<figure>\n<figcaption><b>Ground truth (male)</b></figcaption>\n\t<audio controls\n\t\tsrc=\"/777eaaf8d857127edec70b43f2ed9956/A_SOURCE_male_JP.wav\">\n\t</audio>\n</figure>\n<figure>\n<figcaption><b>Reconstruction (male)</b></figcaption>\n<figcaption>Generator trained using space <b>Zc = 4</b></figcaption>\n\t<audio controls\n\t\tsrc=\"/82d89445780c6603413fcca756fd0ab3/A_Z4_RECON_male_JP.wav\">\n\t</audio>\n</figure>\n<figure>\n<figcaption><b>Voice Conversion (male &rarr; female)</b></figcaption>\n<figcaption>4 examples generated with a trained model using space <b>Zc = 4</b></figcaption>\n\t<audio controls\n\t\tsrc=\"/02bf553b94e4ddc9aaf912710b4c19e9/A4_Z4_male_female_JP.wav\">\n\t</audio>\n\t<audio controls\n\t\tsrc=\"/291e053b5d306984ce34a4ca590bbb6d/A3_Z4_male_female_JP.wav\">\n\t</audio>\n\t<audio controls\n\t\tsrc=\"/af32cb694db90e90c8e27e85845cb05d/A2_Z4_male_female_JP.wav\">\n\t</audio>\n\t<audio controls\n\t\tsrc=\"/42cb8bcb7224fd6e83bdcfb206819898/A1_Z4_male_female_JP.wav\">\n\t</audio>\n\t<figcaption>Above examples show varied timbres and successful conversions to different singers</figcaption>\n</figure>\n<figure>\n<figcaption><b>Voice Conversion (male &rarr; male)</b></figcaption>\n<figcaption>4 examples generated with a trained model using space <b>Zc = 4</b></figcaption>\n\t<audio controls\n\t\tsrc=\"/11c61cd98c665f1bb01e9ac1df4aafab/A1_Z4_male_male_JP.wav\">\n\t</audio>\n\t<audio controls\n\t\tsrc=\"/f47f8b0e0369df05e4e9c68bfab6912b/A3_Z4_male_male_JP.wav\">\n\t</audio>\n\t<audio controls\n\t\tsrc=\"/b49cf6fb7f670f266821b3792e469952/A2_Z4_male_male_JP.wav\">\n\t</audio>\n\t<audio controls\n\t\tsrc=\"/d3faf8e9c988da241fd277a8ff18d3bd/A4_Z4_male_male_JP.wav\">\n\t</audio>\n\t<figcaption>Above examples show varied timbres and successful conversions to different singers</figcaption>\n</figure>\n<figure>\n<figcaption><b>Voice Conversion (male &rarr; female)</b></figcaption>\n<figcaption>Generator trained using space <b>Zc = 100</b></figcaption>\n\t<audio controls\n\t\tsrc=\"/c256cd88fb649e8572ab7f6861524c24/A4_Z100_male_female_JP.wav\">\n\t</audio>\n<figcaption>Example sounds almost the same as the ground truth with <b>no voice conversion</b></figcaption>\n</figure>\n<h1>NUS-48E Dataset - Female (Song 13 &#x26; ID 03)</h1>\n<p>Each presented audio example follows song and singer IDs in the original NUS-48E dataset paper [1]. All examples are 16-bit 22050 Hz WAV files.</p>\n<figure>\n<figcaption><b>Ground truth (female)</b></figcaption>\n\t<audio controls\n\t\tsrc=\"/a2c4984f45c0d226c6d880f04fd24e8f/A_SOURCE_female_EN.wav\">\n\t</audio>\n</figure>\n<figure>\n<figcaption><b>Reconstruction (female)</b></figcaption>\n<figcaption>Generator trained using space <b>Zc = 4</b></figcaption>\n\t<audio controls\n\t\tsrc=\"/350a05c4f669623571cfc28a855cf104/A_Z4_RECON_female_EN.wav\">\n\t</audio>\n</figure>\n<figure>\n<figcaption><b>Voice Conversion (female &rarr; female)</b></figcaption>\n<figcaption>4 examples generated with a trained model using space <b>Zc = 4</b></figcaption>\n\t<audio controls\n\t\tsrc=\"/8ab87d418ccf41a6a2201fa1b97fa728/A4_Z4_female_female_EN.wav\">\n\t</audio>\n\t<audio controls\n\t\tsrc=\"/dccc4df2fa6ae747e9529ea84deb97e7/A3_Z4_female_female_EN.wav\">\n\t</audio>\n\t<audio controls\n\t\tsrc=\"/c57d12cf27cef182d95b629a19d55f98/A2_Z4_female_female_EN.wav\">\n\t</audio>\n\t<audio controls\n\t\tsrc=\"/db01ed0d7b338f63bef626f24e8ddeb8/A1_Z4_female_female_EN.wav\">\n\t</audio>\n\t<figcaption>Above examples show varied timbres and successful conversions to different singers</figcaption>\n</figure>\n<figure>\n<figcaption><b>Voice Conversion (female &rarr; male)</b></figcaption>\n<figcaption>4 examples generated with a trained model using space <b>Zc = 4</b></figcaption>\n\t<audio controls\n\t\tsrc=\"/3a2aaebc3b2dc1e37ee626654f61a7a8/A4_Z4_female_male_EN.wav\">\n\t</audio>\n\t<audio controls\n\t\tsrc=\"/df6c927fffc03b27c967d0ba53e14723/A3_Z4_female_male_EN.wav\">\n\t</audio>\n\t<audio controls\n\t\tsrc=\"/3114f9db09f0ccb73513b25aa41564c1/A2_Z4_female_male_EN.wav\">\n\t</audio>\n\t<audio controls\n\t\tsrc=\"/deaa936ec236b067546f0d54aee80804/A1_Z4_female_male_EN.wav\">\n\t</audio>\n\t<figcaption>Above examples show varied timbres and successful conversions to different singers</figcaption>\n</figure>\n<figure>\n<figcaption><b>Voice Conversion (female &rarr; male)</b></figcaption>\n<figcaption>Generator trained using space <b>Zc = 100</b></figcaption>\n\t<audio controls\n\t\tsrc=\"/66c76b2e6117ae05c15614fa78b47fe7/A1_Z100_female_male_EN.wav\">\n\t</audio>\n<figcaption>Example sounds almost the same as the ground truth with <b>no voice conversion</b></figcaption>\n</figure>\n<h1>NUS-48E Dataset - Male (Song 13 &#x26; ID 03)</h1>\n<p>Each presented audio example follows song and singer IDs in the original NUS-48E dataset paper [1]. All examples are 16-bit 22050 Hz WAV files.</p>\n<figure>\n<figcaption><b>Ground truth (male)</b></figcaption>\n\t<audio controls\n\t\tsrc=\"/0de36fe393d7a1030f7c0b93e1ba1ad2/A_SOURCE_male_EN.wav\">\n\t</audio>\n</figure>\n<figure>\n<figcaption><b>Reconstruction (male)</b></figcaption>\n<figcaption>Generator trained using space <b>Zc = 4</b></figcaption>\n\t<audio controls\n\t\tsrc=\"/30f3bddb135909dded859dab5f8895ca/A_Z4_RECON_male_EN.wav\">\n\t</audio>\n</figure>\n<figure>\n<figcaption><b>Voice Conversion (male &rarr; female)</b></figcaption>\n<figcaption>4 examples generated with a trained model using space <b>Zc = 4</b></figcaption>\n\t<audio controls\n\t\tsrc=\"/a4a0387cfea584fd306a27336356237d/A4_Z4_male_female_EN.wav\">\n\t</audio>\n\t<audio controls\n\t\tsrc=\"/347b18dde7f7b9edf65dc40eb8aa133e/A3_Z4_male_female_EN.wav\">\n\t</audio>\n\t<audio controls\n\t\tsrc=\"/554001cdcf1f2da765a5df2001b3d5d1/A2_Z4_male_female_EN.wav\">\n\t</audio>\n\t<audio controls\n\t\tsrc=\"/9600978c0728d146ac70538c9e56bb2e/A1_Z4_male_female_EN.wav\">\n\t</audio>\n\t<figcaption>Above examples show varied timbres and successful conversions to different singers</figcaption>\n</figure>\n<figure>\n<figcaption><b>Voice Conversion (male &rarr; male)</b></figcaption>\n<figcaption>4 examples generated with a trained model using space <b>Zc = 4</b></figcaption>\n\t<audio controls\n\t\tsrc=\"/218490b3b739dc6926b21f0d28d738b6/A1_Z4_male_male_EN.wav\">\n\t</audio>\n\t<audio controls\n\t\tsrc=\"/6e5df02c893cdc7c818ac3573b2bc6e1/A3_Z4_male_male_EN.wav\">\n\t</audio>\n\t<audio controls\n\t\tsrc=\"/3f8e8b8ab61c8c40be1e295196794c5d/A2_Z4_male_male_EN.wav\">\n\t</audio>\n\t<audio controls\n\t\tsrc=\"/a752097a5260c8527451e5f87bd2378b/A4_Z4_male_male_EN.wav\">\n\t</audio>\n\t<figcaption>Above examples show varied timbres and successful conversions to different singers</figcaption>\n</figure>\n<figure>\n<figcaption><b>Voice Conversion (male &rarr; female)</b></figcaption>\n<figcaption>Generator trained using space <b>Zc = 100</b></figcaption>\n\t<audio controls\n\t\tsrc=\"/714e82a97469c6856baf67ce2184a0b9/A4_Z100_male_female_EN.wav\">\n\t</audio>\n<figcaption>Example sounds almost the same as the ground truth with <b>no voice conversion</b></figcaption>\n</figure>\n<h3>References</h3>\n<p>[1]  <a href=\"https://smcnus.comp.nus.edu.sg/nus-48e-sung-and-spoken-lyrics-corpus/\">Zhiyan Duan et al. “The NUS sung and spoken lyrics corpus: A quantitative comparison of singing and speech”. In: IEEE Asia-Pacific Signal and InformationProcessing Association Annual Summit and Conference (APSIPA ASC). 2013.</a></p>","frontmatter":{"title":"Audio examples","date":"July 17, 2020","tags":["demo"],"description":"Audio examples accompanying paper ID 192 for the 19th International Conference of Machine Learning and Applications."}}},"pageContext":{"isCreatedByStatefulCreatePages":false,"slug":"/demo/","previous":null,"next":null}}}