<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title><![CDATA[192]]></title><description><![CDATA[A blog for minimalist]]></description><link>https://icmla2020192.github.io</link><generator>GatsbyJS</generator><lastBuildDate>Wed, 22 Jul 2020 13:55:59 GMT</lastBuildDate><item><title><![CDATA[Audio examples]]></title><description><![CDATA[Audio examples accompanying paper ID 192 for 19th International Conference of Machine Learning and Applications. While listening to the…]]></description><link>https://icmla2020192.github.io/demo/</link><guid isPermaLink="false">https://icmla2020192.github.io/demo/</guid><pubDate>Fri, 17 Jul 2020 22:20:00 GMT</pubDate><content:encoded>&lt;p&gt;Audio examples accompanying paper ID 192 for 19th International Conference of Machine Learning and Applications.&lt;/p&gt;
&lt;p&gt;While listening to the following audio examples, please note that some sonic artifacts are present here and also in other state-of-the-art singing voice conversion methods (e.g., &lt;a href=&quot;#ref&quot;&gt;1&lt;/a&gt;). The reduction of such artifacts is not the main target of our research and will be tackled by a research community in the future.&lt;/p&gt;
&lt;h1&gt;JPSV-120E Dataset - Female (Song 13 &amp;#x26; ID 27)&lt;/h1&gt;
&lt;p&gt;Each presented audio example follows song and singer IDs in Tables I and II in the paper. All examples are 16-bit 22050 Hz WAV files.&lt;/p&gt;
&lt;figure&gt;
&lt;figcaption&gt;&lt;b&gt;Ground truth (female)&lt;/b&gt;&lt;/figcaption&gt;
	&lt;audio controls
		src=&quot;/4663f12e58405beba0696177a7689aeb/A_SOURCE_female_JP.wav&quot;&gt;
	&lt;/audio&gt;
&lt;/figure&gt;
&lt;figure&gt;
&lt;figcaption&gt;&lt;b&gt;Reconstruction (female)&lt;/b&gt;&lt;/figcaption&gt;
&lt;figcaption&gt;Generator trained using space &lt;b&gt;Zc = 4&lt;/b&gt;&lt;/figcaption&gt;
	&lt;audio controls
		src=&quot;/b8f06b10a172d58ec329ff30471eec9e/A_Z4_RECON_female_JP.wav&quot;&gt;
	&lt;/audio&gt;
&lt;/figure&gt;
&lt;figure&gt;
&lt;figcaption&gt;&lt;b&gt;Voice Conversion (female &amp;rarr; female)&lt;/b&gt;&lt;/figcaption&gt;
&lt;figcaption&gt;4 examples generated with a trained model using space &lt;b&gt;Zc = 4&lt;/b&gt;&lt;/figcaption&gt;
	&lt;audio controls
		src=&quot;/3e47b5ab775b91687feb46a790a9020f/A4_Z4_female_female_JP.wav&quot;&gt;
	&lt;/audio&gt;
	&lt;audio controls
		src=&quot;/c359f14ba8f18a35a8c13db30f435597/A3_Z4_female_female_JP.wav&quot;&gt;
	&lt;/audio&gt;
	&lt;audio controls
		src=&quot;/1ffc5d340c0ecaf3214e58daabe95bc9/A2_Z4_female_female_JP.wav&quot;&gt;
	&lt;/audio&gt;
	&lt;audio controls
		src=&quot;/ed900bb0df13fbba88dd1e9db97fc108/A1_Z4_female_female_JP.wav&quot;&gt;
	&lt;/audio&gt;
	&lt;figcaption&gt;Above examples show varied timbres and successful conversions to different singers&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;figure&gt;
&lt;figcaption&gt;&lt;b&gt;Voice Conversion (female &amp;rarr; male)&lt;/b&gt;&lt;/figcaption&gt;
&lt;figcaption&gt;4 examples generated with a trained model using space &lt;b&gt;Zc = 4&lt;/b&gt;&lt;/figcaption&gt;
	&lt;audio controls
		src=&quot;/8fbbb81436adb08ffa3d9058bb582de3/A4_Z4_female_male_JP.wav&quot;&gt;
	&lt;/audio&gt;
	&lt;audio controls
		src=&quot;/2c813a7402bec7c7f66596274f6f0ade/A3_Z4_female_male_JP.wav&quot;&gt;
	&lt;/audio&gt;
	&lt;audio controls
		src=&quot;/32dd2c65980c1c77706b48b43c064d06/A2_Z4_female_male_JP.wav&quot;&gt;
	&lt;/audio&gt;
	&lt;audio controls
		src=&quot;/410176c5111cf8f85a2354999ea5a81e/A1_Z4_female_male_JP.wav&quot;&gt;
	&lt;/audio&gt;
	&lt;figcaption&gt;Above examples show varied timbres and successful conversions to different singers&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;figure&gt;
&lt;figcaption&gt;&lt;b&gt;Voice Conversion (female &amp;rarr; male)&lt;/b&gt;&lt;/figcaption&gt;
&lt;figcaption&gt;Generator trained using space &lt;b&gt;Zc = 100&lt;/b&gt;&lt;/figcaption&gt;
	&lt;audio controls
		src=&quot;/cdadbf474ae11634f903c9cb6f5eac6d/A1_Z100_female_male_JP.wav&quot;&gt;
	&lt;/audio&gt;
&lt;figcaption&gt;Example sounds almost the same as the ground truth with &lt;b&gt;no voice conversion&lt;/b&gt;&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;h1&gt;JPSV-120E Dataset - Male (Song 56 &amp;#x26; ID 04)&lt;/h1&gt;
&lt;p&gt;Each presented audio example follows song and singer IDs in Tables I and II in the paper. All examples are 16-bit 22050 Hz WAV files.&lt;/p&gt;
&lt;figure&gt;
&lt;figcaption&gt;&lt;b&gt;Ground truth (male)&lt;/b&gt;&lt;/figcaption&gt;
	&lt;audio controls
		src=&quot;/777eaaf8d857127edec70b43f2ed9956/A_SOURCE_male_JP.wav&quot;&gt;
	&lt;/audio&gt;
&lt;/figure&gt;
&lt;figure&gt;
&lt;figcaption&gt;&lt;b&gt;Reconstruction (male)&lt;/b&gt;&lt;/figcaption&gt;
&lt;figcaption&gt;Generator trained using space &lt;b&gt;Zc = 4&lt;/b&gt;&lt;/figcaption&gt;
	&lt;audio controls
		src=&quot;/3f0dd5c401ebfb24cdfcb201e4adc267/A_Z4_RECON_male_JP.wav&quot;&gt;
	&lt;/audio&gt;
&lt;/figure&gt;
&lt;figure&gt;
&lt;figcaption&gt;&lt;b&gt;Voice Conversion (male &amp;rarr; female)&lt;/b&gt;&lt;/figcaption&gt;
&lt;figcaption&gt;4 examples generated with a trained model using space &lt;b&gt;Zc = 4&lt;/b&gt;&lt;/figcaption&gt;
	&lt;audio controls
		src=&quot;/02bf553b94e4ddc9aaf912710b4c19e9/A4_Z4_male_female_JP.wav&quot;&gt;
	&lt;/audio&gt;
	&lt;audio controls
		src=&quot;/291e053b5d306984ce34a4ca590bbb6d/A3_Z4_male_female_JP.wav&quot;&gt;
	&lt;/audio&gt;
	&lt;audio controls
		src=&quot;/af32cb694db90e90c8e27e85845cb05d/A2_Z4_male_female_JP.wav&quot;&gt;
	&lt;/audio&gt;
	&lt;audio controls
		src=&quot;/42cb8bcb7224fd6e83bdcfb206819898/A1_Z4_male_female_JP.wav&quot;&gt;
	&lt;/audio&gt;
	&lt;figcaption&gt;Above examples show varied timbres and successful conversions to different singers&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;figure&gt;
&lt;figcaption&gt;&lt;b&gt;Voice Conversion (male &amp;rarr; male)&lt;/b&gt;&lt;/figcaption&gt;
&lt;figcaption&gt;4 examples generated with a trained model using space &lt;b&gt;Zc = 4&lt;/b&gt;&lt;/figcaption&gt;
	&lt;audio controls
		src=&quot;/11c61cd98c665f1bb01e9ac1df4aafab/A1_Z4_male_male_JP.wav&quot;&gt;
	&lt;/audio&gt;
	&lt;audio controls
		src=&quot;/f47f8b0e0369df05e4e9c68bfab6912b/A3_Z4_male_male_JP.wav&quot;&gt;
	&lt;/audio&gt;
	&lt;audio controls
		src=&quot;/b49cf6fb7f670f266821b3792e469952/A2_Z4_male_male_JP.wav&quot;&gt;
	&lt;/audio&gt;
	&lt;audio controls
		src=&quot;/d3faf8e9c988da241fd277a8ff18d3bd/A4_Z4_male_male_JP.wav&quot;&gt;
	&lt;/audio&gt;
	&lt;figcaption&gt;Above examples show varied timbres and successful conversions to different singers&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;figure&gt;
&lt;figcaption&gt;&lt;b&gt;Voice Conversion (male &amp;rarr; female)&lt;/b&gt;&lt;/figcaption&gt;
&lt;figcaption&gt;Generator trained using space &lt;b&gt;Zc = 100&lt;/b&gt;&lt;/figcaption&gt;
	&lt;audio controls
		src=&quot;/c256cd88fb649e8572ab7f6861524c24/A4_Z100_male_female_JP.wav&quot;&gt;
	&lt;/audio&gt;
&lt;figcaption&gt;Example sounds almost the same as the ground truth with &lt;b&gt;no voice conversion&lt;/b&gt;&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;h1&gt;NUS-48E Dataset - Female (Song 18 &amp;#x26; ID ADIZ)&lt;/h1&gt;
&lt;p&gt;Each presented audio example follows song and singer IDs in the original NUS-48E dataset &lt;a href=&quot;#ref&quot;&gt;2&lt;/a&gt;. All examples are 16-bit 22050 Hz WAV files.&lt;/p&gt;
&lt;figure&gt;
&lt;figcaption&gt;&lt;b&gt;Ground truth (female)&lt;/b&gt;&lt;/figcaption&gt;
	&lt;audio controls
		src=&quot;/a2c4984f45c0d226c6d880f04fd24e8f/A_SOURCE_female_EN.wav&quot;&gt;
	&lt;/audio&gt;
&lt;/figure&gt;
&lt;figure&gt;
&lt;figcaption&gt;&lt;b&gt;Reconstruction (female)&lt;/b&gt;&lt;/figcaption&gt;
&lt;figcaption&gt;Generator trained using space &lt;b&gt;Zc = 4&lt;/b&gt;&lt;/figcaption&gt;
	&lt;audio controls
		src=&quot;/350a05c4f669623571cfc28a855cf104/A_Z4_RECON_female_EN.wav&quot;&gt;
	&lt;/audio&gt;
&lt;/figure&gt;
&lt;figure&gt;
&lt;figcaption&gt;&lt;b&gt;Voice Conversion (female &amp;rarr; female)&lt;/b&gt;&lt;/figcaption&gt;
&lt;figcaption&gt;4 examples generated with a trained model using space &lt;b&gt;Zc = 4&lt;/b&gt;&lt;/figcaption&gt;
	&lt;audio controls
		src=&quot;/8ab87d418ccf41a6a2201fa1b97fa728/A4_Z4_female_female_EN.wav&quot;&gt;
	&lt;/audio&gt;
	&lt;audio controls
		src=&quot;/dccc4df2fa6ae747e9529ea84deb97e7/A3_Z4_female_female_EN.wav&quot;&gt;
	&lt;/audio&gt;
	&lt;audio controls
		src=&quot;/c57d12cf27cef182d95b629a19d55f98/A2_Z4_female_female_EN.wav&quot;&gt;
	&lt;/audio&gt;
	&lt;audio controls
		src=&quot;/db01ed0d7b338f63bef626f24e8ddeb8/A1_Z4_female_female_EN.wav&quot;&gt;
	&lt;/audio&gt;
	&lt;figcaption&gt;Above examples show varied timbres and successful conversions to different singers&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;figure&gt;
&lt;figcaption&gt;&lt;b&gt;Voice Conversion (female &amp;rarr; male)&lt;/b&gt;&lt;/figcaption&gt;
&lt;figcaption&gt;4 examples generated with a trained model using space &lt;b&gt;Zc = 4&lt;/b&gt;&lt;/figcaption&gt;
	&lt;audio controls
		src=&quot;/3a2aaebc3b2dc1e37ee626654f61a7a8/A4_Z4_female_male_EN.wav&quot;&gt;
	&lt;/audio&gt;
	&lt;audio controls
		src=&quot;/df6c927fffc03b27c967d0ba53e14723/A3_Z4_female_male_EN.wav&quot;&gt;
	&lt;/audio&gt;
	&lt;audio controls
		src=&quot;/3114f9db09f0ccb73513b25aa41564c1/A2_Z4_female_male_EN.wav&quot;&gt;
	&lt;/audio&gt;
	&lt;audio controls
		src=&quot;/deaa936ec236b067546f0d54aee80804/A1_Z4_female_male_EN.wav&quot;&gt;
	&lt;/audio&gt;
	&lt;figcaption&gt;Above examples show varied timbres and successful conversions to different singers&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;figure&gt;
&lt;figcaption&gt;&lt;b&gt;Voice Conversion (female &amp;rarr; male)&lt;/b&gt;&lt;/figcaption&gt;
&lt;figcaption&gt;Generator trained using space &lt;b&gt;Zc = 100&lt;/b&gt;&lt;/figcaption&gt;
	&lt;audio controls
		src=&quot;/66c76b2e6117ae05c15614fa78b47fe7/A1_Z100_female_male_EN.wav&quot;&gt;
	&lt;/audio&gt;
&lt;figcaption&gt;Example sounds almost the same as the ground truth with &lt;b&gt;no voice conversion&lt;/b&gt;&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;h1&gt;NUS-48E Dataset - Male (Song 15 &amp;#x26; ID JLEE)&lt;/h1&gt;
&lt;p&gt;Each presented audio example follows song and singer IDs in the original NUS-48E dataset &lt;a href=&quot;#ref&quot;&gt;2&lt;/a&gt;. All examples are 16-bit 22050 Hz WAV files.&lt;/p&gt;
&lt;figure&gt;
&lt;figcaption&gt;&lt;b&gt;Ground truth (male)&lt;/b&gt;&lt;/figcaption&gt;
	&lt;audio controls
		src=&quot;/0de36fe393d7a1030f7c0b93e1ba1ad2/A_SOURCE_male_EN.wav&quot;&gt;
	&lt;/audio&gt;
&lt;/figure&gt;
&lt;figure&gt;
&lt;figcaption&gt;&lt;b&gt;Reconstruction (male)&lt;/b&gt;&lt;/figcaption&gt;
&lt;figcaption&gt;Generator trained using space &lt;b&gt;Zc = 4&lt;/b&gt;&lt;/figcaption&gt;
	&lt;audio controls
		src=&quot;/30f3bddb135909dded859dab5f8895ca/A_Z4_RECON_male_EN.wav&quot;&gt;
	&lt;/audio&gt;
&lt;/figure&gt;
&lt;figure&gt;
&lt;figcaption&gt;&lt;b&gt;Voice Conversion (male &amp;rarr; female)&lt;/b&gt;&lt;/figcaption&gt;
&lt;figcaption&gt;4 examples generated with a trained model using space &lt;b&gt;Zc = 4&lt;/b&gt;&lt;/figcaption&gt;
	&lt;audio controls
		src=&quot;/a4a0387cfea584fd306a27336356237d/A4_Z4_male_female_EN.wav&quot;&gt;
	&lt;/audio&gt;
	&lt;audio controls
		src=&quot;/347b18dde7f7b9edf65dc40eb8aa133e/A3_Z4_male_female_EN.wav&quot;&gt;
	&lt;/audio&gt;
	&lt;audio controls
		src=&quot;/554001cdcf1f2da765a5df2001b3d5d1/A2_Z4_male_female_EN.wav&quot;&gt;
	&lt;/audio&gt;
	&lt;audio controls
		src=&quot;/9600978c0728d146ac70538c9e56bb2e/A1_Z4_male_female_EN.wav&quot;&gt;
	&lt;/audio&gt;
	&lt;figcaption&gt;Above examples show varied timbres and successful conversions to different singers&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;figure&gt;
&lt;figcaption&gt;&lt;b&gt;Voice Conversion (male &amp;rarr; male)&lt;/b&gt;&lt;/figcaption&gt;
&lt;figcaption&gt;4 examples generated with a trained model using space &lt;b&gt;Zc = 4&lt;/b&gt;&lt;/figcaption&gt;
	&lt;audio controls
		src=&quot;/218490b3b739dc6926b21f0d28d738b6/A1_Z4_male_male_EN.wav&quot;&gt;
	&lt;/audio&gt;
	&lt;audio controls
		src=&quot;/6e5df02c893cdc7c818ac3573b2bc6e1/A3_Z4_male_male_EN.wav&quot;&gt;
	&lt;/audio&gt;
	&lt;audio controls
		src=&quot;/3f8e8b8ab61c8c40be1e295196794c5d/A2_Z4_male_male_EN.wav&quot;&gt;
	&lt;/audio&gt;
	&lt;audio controls
		src=&quot;/a752097a5260c8527451e5f87bd2378b/A4_Z4_male_male_EN.wav&quot;&gt;
	&lt;/audio&gt;
	&lt;figcaption&gt;Above examples show varied timbres and successful conversions to different singers&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;figure&gt;
&lt;figcaption&gt;&lt;b&gt;Voice Conversion (male &amp;rarr; female)&lt;/b&gt;&lt;/figcaption&gt;
&lt;figcaption&gt;Generator trained using space &lt;b&gt;Zc = 100&lt;/b&gt;&lt;/figcaption&gt;
	&lt;audio controls
		src=&quot;/714e82a97469c6856baf67ce2184a0b9/A4_Z100_male_female_EN.wav&quot;&gt;
	&lt;/audio&gt;
&lt;figcaption&gt;Example sounds almost the same as the ground truth with &lt;b&gt;no voice conversion&lt;/b&gt;&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;h1&gt;&lt;a name=&quot;ref&quot;&gt;References&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;[1] &lt;a href=&quot;https://ismir19-217.github.io/icassp20-audio-sample/&quot;&gt;Yin-Jyun Luo et al. “Singing voice conversion with disentangled representations of singer and vocal technique using variational autoencoders”. In: IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). 2020.&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[2]  &lt;a href=&quot;https://smcnus.comp.nus.edu.sg/nus-48e-sung-and-spoken-lyrics-corpus/&quot;&gt;Zhiyan Duan et al. “The NUS sung and spoken lyrics corpus: A quantitative comparison of singing and speech”. In: IEEE Asia-Pacific Signal and InformationProcessing Association Annual Summit and Conference (APSIPA ASC). 2013.&lt;/a&gt;&lt;/p&gt;</content:encoded></item></channel></rss>